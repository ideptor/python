{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65e2033d-923e-4cd0-89ae-75887e976088",
      "metadata": {
        "id": "65e2033d-923e-4cd0-89ae-75887e976088"
      },
      "source": [
        "# import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da90114-3190-4f61-bb92-f2e2d50fac38",
      "metadata": {
        "id": "1da90114-3190-4f61-bb92-f2e2d50fac38"
      },
      "outputs": [],
      "source": [
        "import mnist_train as mt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7367d37-0217-4be1-8148-d837a6483a2b",
      "metadata": {
        "id": "d7367d37-0217-4be1-8148-d837a6483a2b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d67f599-b71f-4b5c-b3e5-efe219292e01",
      "metadata": {
        "id": "6d67f599-b71f-4b5c-b3e5-efe219292e01"
      },
      "source": [
        "# GPU check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6383691-efe1-42f4-8183-e8ee723aed31",
      "metadata": {
        "id": "d6383691-efe1-42f4-8183-e8ee723aed31"
      },
      "outputs": [],
      "source": [
        "print(\"torch.cuda.is_availible(): \", torch.cuda.is_available())\n",
        "print(\"torch.cuda.get_device_name(): \", torch.cuda.get_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb6731c-7708-49a3-960c-f4c85fd91403",
      "metadata": {
        "id": "bbb6731c-7708-49a3-960c-f4c85fd91403"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1916d001-809e-42bb-ae24-f1c315c67ceb",
      "metadata": {
        "id": "1916d001-809e-42bb-ae24-f1c315c67ceb"
      },
      "source": [
        "# Download MNIST dataset\n",
        "\n",
        "## What is MNIST dataset?\n",
        "> MNIST 데이터베이스 (Modified National Institute of Standards and Technology database)는  \n",
        "손으로 쓴 숫자들로 이루어진 대형 데이터베이스이며,   \n",
        "다양한 화상 처리 시스템을 트레이닝하기 위해 일반적으로 사용된다.   \n",
        "이 데이터베이스는 또한 기계 학습 분야의 트레이닝 및 테스트에 널리 사용된다.  \n",
        ">  \n",
        "> https://ko.wikipedia.org/wiki/MNIST_데이터베이스"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c19425-48cb-40dd-a283-ad681386acb5",
      "metadata": {
        "id": "60c19425-48cb-40dd-a283-ad681386acb5"
      },
      "source": [
        "\n",
        "> `Dataset` 은 샘플과 정답(label)을 저장하기 위한 목적으로 사용됩니다.  \n",
        "https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1139dcb5-e7f8-4673-ad13-d30fd4186ae9",
      "metadata": {
        "id": "1139dcb5-e7f8-4673-ad13-d30fd4186ae9"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# local에 데이터가 없으면 다운로드 받음\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,                         \n",
        "    transform = ToTensor(), \n",
        "    download = True,            \n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data', \n",
        "    train = False, \n",
        "    transform = ToTensor()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e3bcea-8819-4f8c-b1b3-b3057084caf2",
      "metadata": {
        "id": "b6e3bcea-8819-4f8c-b1b3-b3057084caf2"
      },
      "outputs": [],
      "source": [
        "print(train_data)\n",
        "print(\"----\")\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edafa489-8bf6-4dd2-bb1d-a9178f47964f",
      "metadata": {
        "id": "edafa489-8bf6-4dd2-bb1d-a9178f47964f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "idx = random.randrange(0, len(test_data)-1)\n",
        "\n",
        "img, label = train_data[idx]\n",
        "mt.plot_train_data(img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5082700-1d3b-422a-b87c-3ef5a42cc2e2",
      "metadata": {
        "id": "d5082700-1d3b-422a-b87c-3ef5a42cc2e2"
      },
      "source": [
        "# Plot multiple train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b682af98-01d8-49fa-8db9-aed5fe8ce9fe",
      "metadata": {
        "id": "b682af98-01d8-49fa-8db9-aed5fe8ce9fe"
      },
      "outputs": [],
      "source": [
        "mt.plot_multiple_train_data(train_data=train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37be9495-e9ad-4e95-98f7-eb7c8394c095",
      "metadata": {
        "id": "37be9495-e9ad-4e95-98f7-eb7c8394c095"
      },
      "source": [
        "# Dataloader\n",
        "\n",
        "> DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.  \n",
        "Dataset 은 데이터셋의 특징(feature)을 가져오고  \n",
        "하나의 샘플에 정답(label)을 지정하는 일을 한 번에 합니다.  \n",
        "모델을 학습할 때, 일반적으로 샘플들을 “미니배치(minibatch)”로 전달하고,  \n",
        "매 에폭(epoch)마다 데이터를 다시 섞어서 과적합(overfit)을 막고,  \n",
        "Python의 multiprocessing 을 사용하여 데이터 검색 속도를 높이려고 합니다.\n",
        ">\n",
        "> DataLoader 는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iterable)입니다  \n",
        "https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abf13b84-bbf5-45d2-8cdc-d232b729f52f",
      "metadata": {
        "id": "abf13b84-bbf5-45d2-8cdc-d232b729f52f"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True),\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, ),\n",
        "}\n",
        "loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b14afa6c-c3b6-4f18-82c8-88e9e7f2d282",
      "metadata": {
        "id": "b14afa6c-c3b6-4f18-82c8-88e9e7f2d282"
      },
      "source": [
        "# Defile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4424a7ed-45a5-4064-883c-f52b752fe63d",
      "metadata": {
        "id": "4424a7ed-45a5-4064-883c-f52b752fe63d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class NN(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(NN, self).__init__()\n",
        "        \n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Linear(in_features, 28*30),      # layer1 - input\n",
        "            nn.ReLU(),         \n",
        "            \n",
        "            nn.Linear(28*30, 30*40),            # layer2 - hidden\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(30*40, 30*40),            # layer3 - hidden\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(40*30, 30*28),            # layer4 - hidden\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(30*28, out_features),     # layer5 - out\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.nn(x) \n",
        "        out = F.softmax(out, dim=1)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371d3e0c-1987-4e63-b082-5e31d3d84bd5",
      "metadata": {
        "id": "371d3e0c-1987-4e63-b082-5e31d3d84bd5"
      },
      "outputs": [],
      "source": [
        "model = NN(28*28, 10)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb4e53f-dc61-4d97-837c-110702a22b31",
      "metadata": {
        "id": "feb4e53f-dc61-4d97-837c-110702a22b31"
      },
      "outputs": [],
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(28*28,))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d17e9c-f33d-497c-b7d0-15932c6cb261",
      "metadata": {
        "id": "53d17e9c-f33d-497c-b7d0-15932c6cb261"
      },
      "source": [
        "# model test (before training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34df78f9-01a3-46c6-9b25-e31c49d1f1d6",
      "metadata": {
        "id": "34df78f9-01a3-46c6-9b25-e31c49d1f1d6"
      },
      "outputs": [],
      "source": [
        "mt.show_sample_predict_nn(model, device, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d46da9-da0b-4851-83b3-e3c6b540d8dd",
      "metadata": {
        "id": "25d46da9-da0b-4851-83b3-e3c6b540d8dd"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f66efd-83e4-4a4b-8027-8a02224dc020",
      "metadata": {
        "tags": [],
        "id": "e6f66efd-83e4-4a4b-8027-8a02224dc020"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import time\n",
        "\n",
        "def train(model, loaders, num_epochs, loss_func, optimizer, train_loss_list:list, test_loss_list:list):\n",
        "\n",
        "    total_step = len(loaders['train'])      # num of batch\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        loss_dict = {\n",
        "            'train': 0.,\n",
        "            'test': 0.\n",
        "        }        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        for phase in ['train', 'test']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "        \n",
        "            # batch size단위로 학습하기\n",
        "            for i, (images, labels) in enumerate(loaders[phase]):\n",
        "\n",
        "                images = images.to(device, dtype=torch.float32)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # iteration\n",
        "                loss = 0    # iteration loss\n",
        "                for idx in range(len(images)):\n",
        "                    image = images[idx]\n",
        "                    image = image.view(1, -1)\n",
        "                    output = model(image)\n",
        "                    loss =+ loss_func(output, labels.unsqueeze(1)[idx])\n",
        "\n",
        "                loss_dict[phase] += loss.item()\n",
        "                \n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()     # clear gradients for this training step               \n",
        "                    loss.backward()           # backpropagation, compute gradients         \n",
        "                    optimizer.step()          # apply gradients                 \n",
        "\n",
        "                    # batch 100번 마다 로그 찍기\n",
        "                    if (i+1) % 100 == 0:\n",
        "                        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.6f}' \n",
        "                               .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "        \n",
        "                \n",
        "        train_loss = loss_dict['train'] / len(loaders['train']) \n",
        "        test_loss = loss_dict['test'] / len(loaders['test']) \n",
        "\n",
        "        # test_loss가 가장 작을때의 weight 를 저장\n",
        "        if epoch == 0:\n",
        "            min_loss = test_loss\n",
        "            best_model = model.state_dict()\n",
        "        elif test_loss < min_loss:\n",
        "            min_loss = test_loss\n",
        "            best_model = model.state_dict()\n",
        "                        \n",
        "        train_loss_list.append(train_loss)\n",
        "        test_loss_list.append(test_loss)\n",
        "        duration = time.time() - start_time\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] summary, train_loss:{train_loss:8.8f}, \"\\\n",
        "              f\"test_loss:{test_loss:8.8f} duration: {duration:.1f}s\")\n",
        "\n",
        "    # test_loss가 가장 작을때의 weight 로 복원\n",
        "    model.load_state_dict(best_model)\n",
        "        \n",
        "    return model, train_loss_list, test_loss_list\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef333f9-dbe1-43d1-b1b6-891f78c5a373",
      "metadata": {
        "id": "2ef333f9-dbe1-43d1-b1b6-891f78c5a373"
      },
      "outputs": [],
      "source": [
        "model = NN(28*28, 10)\n",
        "model = model.to(device)\n",
        "loss_func = nn.CrossEntropyLoss()   \n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001)   \n",
        "\n",
        "train_loss_list = []\n",
        "test_loss_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93c3b44-1d15-46e4-8a69-fa1891dd7e22",
      "metadata": {
        "id": "e93c3b44-1d15-46e4-8a69-fa1891dd7e22"
      },
      "outputs": [],
      "source": [
        "model, train_loss_list, test_loss_list = train(model, loaders, 10, loss_func, optimizer, train_loss_list, test_loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8c37b8-e263-432a-a792-a7604a559eda",
      "metadata": {
        "id": "fc8c37b8-e263-432a-a792-a7604a559eda"
      },
      "outputs": [],
      "source": [
        "mt.draw_loss(train_loss_list, test_loss_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9fc606c-43f5-4241-9915-cebc0a786d0a",
      "metadata": {
        "tags": [],
        "id": "c9fc606c-43f5-4241-9915-cebc0a786d0a"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a2b62a-fdd3-4a66-8199-69a7b325c1ba",
      "metadata": {
        "id": "80a2b62a-fdd3-4a66-8199-69a7b325c1ba"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def evaluate():\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for images, labels in tqdm(loaders['test']):\n",
        "            images = images.to(device, dtype=torch.float32)\n",
        "            labels = labels.to(device)\n",
        "            for idx in range(len(images)):\n",
        "                image = images[idx].view(1,-1)\n",
        "                output = model(image)  \n",
        "                pred = torch.max(output, 1)[1].item()\n",
        "                total += 1\n",
        "                if pred == labels[idx].item():\n",
        "                    correct+=1\n",
        "                \n",
        "        print(f'Test Accuracy of the model on the 10000 test images: {correct/total*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af29076-f2b4-4353-811f-eae705b22d96",
      "metadata": {
        "id": "5af29076-f2b4-4353-811f-eae705b22d96"
      },
      "outputs": [],
      "source": [
        "evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "909d7002-3c49-4593-aefd-aeb86e6f2fec",
      "metadata": {
        "tags": [],
        "id": "909d7002-3c49-4593-aefd-aeb86e6f2fec"
      },
      "source": [
        "# Evaluation data sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd64225a-d991-439b-91fc-ad4593b6c75d",
      "metadata": {
        "id": "dd64225a-d991-439b-91fc-ad4593b6c75d"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "    model.eval()\n",
        "    sample_idx = np.random.randint(len(test_data), size=(1,)).item()\n",
        "    img, gt = test_data[sample_idx]\n",
        "    img = img.to(device)\n",
        "\n",
        "    predicted = model(img.view(1,-1))\n",
        "    label = torch.argmax(predicted)\n",
        "\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(f\"{label} (GT:{gt} / {gt==label})\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.view(28,28).cpu(), cmap=\"gray\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd981c5-661e-4e88-a821-8d9bf86de54f",
      "metadata": {
        "id": "bdd981c5-661e-4e88-a821-8d9bf86de54f"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8ceadc-cf6a-4a6c-9936-c2cebb233053",
      "metadata": {
        "id": "5c8ceadc-cf6a-4a6c-9936-c2cebb233053"
      },
      "outputs": [],
      "source": [
        "mt.show_sample_predict_nn(model, device, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c50bd3b8-79bb-4fa6-9e27-f82f80d7a6b9",
      "metadata": {
        "id": "c50bd3b8-79bb-4fa6-9e27-f82f80d7a6b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42b9f55-d4c8-486b-be0b-5b0764b4c05c",
      "metadata": {
        "id": "f42b9f55-d4c8-486b-be0b-5b0764b4c05c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}