{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w4_nn.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU 실습\n",
        "## GPU 사용 가능여부 확인"
      ],
      "metadata": {
        "id": "a0UnYDIAcJQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"torch.cuda.is_availible(): \", torch.cuda.is_available())\n",
        "print(\"torch.cuda.get_device_name(): \", torch.cuda.get_device_name())"
      ],
      "metadata": {
        "id": "Rx0lVV42dbDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU와 CPU 성능 확인\n",
        "\n",
        "> 1000 * 1000 matrix 연산\n",
        "\n",
        "Ctrl + Enter를 눌러서 반복 실행해보세요"
      ],
      "metadata": {
        "id": "NyHK-vUHdisl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  \n",
        "    x = torch.ones(1000, 1000).to(torch.device(\"cpu\"))  # 1000x1000 배열에 1을 채우고 CPU 동작모드로 설정\n",
        "    y = 2 * x + 3\n",
        "    start_time = time.time()\n",
        "  \n",
        "    # Matrix multiplication (for benchmark purpose)\n",
        "    results = torch.mm(x, y)\n",
        "    time_cpu = time.time() - start_time\n",
        "\n",
        "    # Do the same calculation but on the gpu\n",
        "    # First move tensors to gpu\n",
        "    # CUDA(Compute Unified Device Architecture) - NVDIA 에서 만든 GPU 에서 수행하는 병렬처리 알고리즘\n",
        "    x = x.to(\"cuda\")   # 1000 * 1000 메트릭스를 GPU 모드로 설정\n",
        "    y = y.to(\"cuda\")\n",
        "    start_time = time.time()\n",
        "    # Matrix multiplication (for benchmark purpose)\n",
        "    results = torch.mm(x, y)\n",
        "    time_gpu = time.time() - start_time\n",
        "    if time_gpu == 0:\n",
        "        time_gpu = 0.0000001\n",
        "    print(\"Time on CPU: {:.7f}s \\t Time on GPU: {:.7f}s\".format(time_cpu, time_gpu))\n",
        "    print(\"Speed up: Computation was {:.0f}X faster on GPU!\".format(time_cpu / time_gpu))\n",
        "\n",
        "else:\n",
        "    print(\"You need to enable GPU accelaration in colab (runtime->change runtime type)\")"
      ],
      "metadata": {
        "id": "a9i8eGQodfci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network 실습\n",
        "## 임의좌표 생성"
      ],
      "metadata": {
        "id": "uGYYSPwZw_12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 생성 및 labeling 코드 취합"
      ],
      "metadata": {
        "id": "p7L7LAaSxhRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import random\n",
        "\n",
        "def generate(func, num=100, max=10, val_ratio=0.25):\n",
        "  X = np.random.rand(num,2)\n",
        "  X *= max\n",
        "\n",
        "  data_list = []\n",
        "  for x in X:\n",
        "    label = 0 if x[1] > func(x[0]) else 1\n",
        "    data = {\n",
        "        \"dataset\": \"train\" if random() > val_ratio else \"val\",\n",
        "        \"x0\": x[0],\n",
        "        \"x1\": x[1],\n",
        "        \"label\": label,\n",
        "        \"class0\": 1 if label == 0 else 0,\n",
        "        \"class1\": 1 if label == 1 else 0,\n",
        "    }\n",
        "    data_list.append(data)\n",
        "\n",
        "  df = pd.DataFrame(data_list)\n",
        "  df = df.sort_values(by=\"dataset\")\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "Q1apRu1oimsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계1. 데이터 생성"
      ],
      "metadata": {
        "id": "K91GO8Vixmij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import seaborn as sb\n",
        "\n",
        "def func1(x):\n",
        "  return 0.03 * math.pow(x-4,3) + 3\n",
        "\n",
        "def func2(x):\n",
        "  return 0.7 * math.pow(x-4,2) + 1\n",
        "\n",
        "# df = generate(func1, 100, 10)\n",
        "df = generate(func2, 100, 10)\n",
        "print(df)\n",
        "print(\"Dataset/Label value counts\\n\", df[[\"dataset\", \"label\"]].value_counts())\n",
        "sb.scatterplot(data=df, x=\"x0\", y=\"x1\", hue=\"label\")\n"
      ],
      "metadata": {
        "id": "-51n8rttjX9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계2. pytorch 및 GPU 사용 준비"
      ],
      "metadata": {
        "id": "fH1WlWtsfb0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "torch.__version__\n"
      ],
      "metadata": {
        "id": "-SXUgtnPRI7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"torch.cuda.is_availible(): \", torch.cuda.is_available())\n",
        "print(\"torch.cuda.get_device_name(): \", torch.cuda.get_device_name())"
      ],
      "metadata": {
        "id": "edq8d0RDS59i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "6C9xS5vJS6hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계3. Nueral Network 구성\n",
        "총 5개 layer\n",
        "\n",
        "|Layer|Input|Output|Remarks|\n",
        "|---|---|---|:---:|\n",
        "|1|**2(feature)**|10|ReLU|\n",
        "|2|10|20|ReLU|\n",
        "|3|20|20|ReLU|\n",
        "|4|20|10|ReLU|\n",
        "|5|10|**2(label)**|-|"
      ],
      "metadata": {
        "id": "9BQoPLqRgC6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class NN(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(NN, self).__init__()\n",
        "        \n",
        "        self.nn = nn.Sequential(\n",
        "            nn.Linear(in_features, 10),      # layer1 - input\n",
        "            nn.ReLU(),         \n",
        "            \n",
        "            nn.Linear(10, 20),            # layer2 - hidden\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(20, 20),            # layer3 - hidden\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(20, 10),            # layer4 - hidden\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(10, out_features),     # layer5 - out\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.nn(x) \n",
        "        out = F.softmax(out, dim=1)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def predict(self, x: pd.DataFrame) -> np.ndarray:\n",
        "\n",
        "      x =  torch.from_numpy(x).to(device, dtype=torch.float32)\n",
        "      out = self.forward(x)\n",
        "      out = out.cpu().detach().numpy()\n",
        "      labels = []\n",
        "      for o in out:\n",
        "          labels.append(\n",
        "              0 if o[0] > o[1] else 1\n",
        "          )\n",
        "      return np.array(labels)"
      ],
      "metadata": {
        "id": "1pvso7mNTIIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(in_features=2, out_features=2)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bqVHi_fKTWXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(2,))"
      ],
      "metadata": {
        "id": "DK1N42_nTejw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계4. Nueral Network 학습"
      ],
      "metadata": {
        "id": "UhySQ5yBhwYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def split(df):\n",
        "\n",
        "  return {\n",
        "    \"train\": {\n",
        "      \"features\": df[df[\"dataset\"] == \"train\"][[\"x0\", \"x1\"]].to_numpy(),\n",
        "      \"labels\": df[df[\"dataset\"] == \"train\"][[\"class0\", \"class1\"]].to_numpy()\n",
        "    },\n",
        "    \"val\": {\n",
        "      \"features\":  df[df[\"dataset\"] == \"val\"][[\"x0\", \"x1\"]].to_numpy(),\n",
        "      \"labels\": df[df[\"dataset\"] == \"val\"][[\"class0\", \"class1\"]].to_numpy()\n",
        "    }\n",
        "  }\n",
        "\n",
        "def train(model, df, num_epochs, loss_func, optimizer):\n",
        "\n",
        "    loss_list = []  # 중간 결과값을 보여주기 위해\n",
        "\n",
        "    dataset = split(df)\n",
        "    # total_step = len(df[df['dataset']=='train'])      \n",
        "    \n",
        "    pbar =  tqdm(range(num_epochs))  # progress를 보여주기 위함\n",
        "    for epoch in pbar:\n",
        "        loss_dict = {     # 중간 결과값을 보여주기 위해\n",
        "            'train': 0.,\n",
        "            'val': 0.\n",
        "        }        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()  # backprobagation을 위한 변수들을 활성화\n",
        "            else:\n",
        "                model.eval()    # backpropagation을 위한 변수들을 비활성화\n",
        "\n",
        "            # for i in range(len(features)):\n",
        "\n",
        "            features = torch.from_numpy(dataset[phase][\"features\"]).to(device, dtype=torch.float32)\n",
        "            labels = torch.from_numpy(dataset[phase][\"labels\"]).to(device, dtype=torch.float32)\n",
        "\n",
        "            # iteration\n",
        "            loss = 0    # iteration loss\n",
        "            for idx in range(len(features)):\n",
        "                feature = features[idx]        \n",
        "                feature = feature.view(1, -1)   # NN 모델에 입력하기위한 형태로 변환\n",
        "                output = model(feature)         # NN 모델에 입력\n",
        "                loss =+ loss_func(output, labels.unsqueeze(1)[idx])  # NN모델이 입력한 값과 실제 값의 오차 게산\n",
        "\n",
        "                loss_dict[phase] += loss.item()\n",
        "                \n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()     # 이전 오차계산값 지우기 (clear gradients for this training step)               \n",
        "                    loss.backward()           # 오차계산 (backpropagation, compute gradients)       \n",
        "                    optimizer.step()          # 오차를 계산한 각 neural(layer) 들의 w값 업데이트 (apply gradients)                 \n",
        "\n",
        "                # print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.6f}\") \n",
        "                        \n",
        "        train_loss = loss_dict[\"train\"] / len(dataset[\"train\"][\"features\"]) \n",
        "        val_loss = loss_dict[\"val\"] / len(dataset[\"val\"][\"features\"]) \n",
        "        # test_loss가 가장 작을때의 weight 를 저장\n",
        "        if epoch == 0:\n",
        "            min_loss = val_loss\n",
        "            best_model = model.state_dict()\n",
        "        elif val_loss < min_loss:\n",
        "            min_loss = val_loss\n",
        "            best_model = model.state_dict()\n",
        "        \n",
        "        # 학습 중간과정 출력을 보여주기 위한 코드        \n",
        "        loss_list.extend([\n",
        "            {\"epoch\": epoch, \"loss\": train_loss, \"phase\":\"train\"},\n",
        "            {\"epoch\": epoch, \"loss\": val_loss, \"phase\":\"val\"},\n",
        "        ])\n",
        "\n",
        "        duration = time.time() - start_time # 동작시간 계산\n",
        "        pbar.set_description(\n",
        "              f\"train_loss:{train_loss:.5f}, \"\n",
        "              f\"val_loss:{val_loss:.5f} \"\n",
        "              f\"duration: {duration:.1f}s\"\n",
        "        )\n",
        "\n",
        "    # test_loss가 가장 작을때의 weight 로 복원\n",
        "    model.load_state_dict(best_model)\n",
        "\n",
        "    df = pd.DataFrame(loss_list)\n",
        "        \n",
        "    return model, df\n",
        "        "
      ],
      "metadata": {
        "id": "IXrjfYLgTyOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(2, 2)\n",
        "model = model.to(device)\n",
        "loss_func = nn.CrossEntropyLoss()   \n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001)   \n"
      ],
      "metadata": {
        "id": "GXsjI3hOeshn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, df_loss = train(model, df, 100, loss_func, optimizer)"
      ],
      "metadata": {
        "id": "hlLgFF3BexPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loss.head(5)"
      ],
      "metadata": {
        "id": "INkGlnC-gkmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "sb.lineplot(data=df_loss, x=\"epoch\", y=\"loss\", hue=\"phase\")\n",
        "plt.ylim(0.3,0.8)"
      ],
      "metadata": {
        "id": "HQNXj0U2fZE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plot\n",
        "import numpy as np\n",
        "\n",
        "def draw_graph(classifier, data):\n",
        "  x_min, x_max = data[\"x0\"].min() - 1, data[\"x0\"].max() + 1\n",
        "  y_min, y_max = data[\"x1\"].min() - 1, data[\"x1\"].max() + 1\n",
        "  h = 0.04\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "  Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  plot.figure(figsize=(8, 6))\n",
        "\n",
        "  colormap_light = ListedColormap([\"yellow\", \"orange\"])\n",
        "  plot.contourf(xx, yy, Z, colormap=colormap_light)\n",
        "\n",
        "  colormap_bold = [\"pink\", \"c\"]\n",
        "  sb.scatterplot(\n",
        "      data=data,\n",
        "      x=\"x0\", y=\"x1\",hue=\"label\",\n",
        "      palette=colormap_bold,\n",
        "      alpha=1.0,\n",
        "      edgecolor=\"brown\",\n",
        "  )\n",
        "  plot.xlim(xx.min(), xx.max())\n",
        "  plot.ylim(yy.min(), yy.max())\n",
        "\n",
        "  y_predict = classifier.predict(data[[\"x0\",\"x1\"]].to_numpy())\n",
        "  hit_count=0\n",
        "  for i in range(len(df)):\n",
        "    if y_predict[i] == data['label'].iloc[i]:\n",
        "      hit_count += 1\n",
        "\n",
        "  plot.title(\n",
        "      f\"{str(classifier)} classification \"\n",
        "      f\"\\nacc={hit_count/len(data)*100:.1f} % ({hit_count}/{len(data)})\"\n",
        "  )\n",
        "  # plot.xlabel(iris.feature_names[0])\n",
        "  # plot.ylabel(iris.feature_names[1])"
      ],
      "metadata": {
        "id": "2p-ycyDymsWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계5. 학습결과 확인"
      ],
      "metadata": {
        "id": "SebzPGVEx3vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_graph(classifier=model, data=df)"
      ],
      "metadata": {
        "id": "1cfHosdujV_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data_size, epoch, 등을 변경해가면서 실험"
      ],
      "metadata": {
        "id": "-rGzerICj6Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_experiment(data_size=100, epoch=10, lr=0.0001, func=func1):  \n",
        "\n",
        "  df = generate(func, data_size, 10)\n",
        "\n",
        "  print(f\"# Generated: {data_size}\")\n",
        "  sb.scatterplot(data=df, x=\"x0\", y=\"x1\", hue=\"label\")\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"# Prepare model\")\n",
        "  model = NN(2, 2)\n",
        "  model = model.to(device)\n",
        "  loss_func = nn.CrossEntropyLoss()   \n",
        "  optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  print(\"# Training\")\n",
        "  model, df_loss = train(model, df, epoch, loss_func, optimizer)\n",
        "\n",
        "  print(\"# Training summary\")\n",
        "  sb.lineplot(data=df_loss, x=\"epoch\", y=\"loss\", hue=\"phase\")\n",
        "  plt.ylim(0.3, 0.8)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"# Evaluation\")\n",
        "  df = generate(func, 100, 10)          # 학습때 사용하지 않은 신규 데이터를 생성해서 테스트\n",
        "  draw_graph(classifier=model, data=df)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "k-6ntF7wtRBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_experiment(data_size=100, epoch=100, func=func2)"
      ],
      "metadata": {
        "id": "fjHG8R3rmXM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate를 키웠을때\n",
        "nn_experiment(data_size=100, epoch=100, func=func2, lr=0.005)"
      ],
      "metadata": {
        "id": "37WUwyS3w_X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate를 작게했을때\n",
        "nn_experiment(data_size=100, epoch=100, func=func2, lr=0.00005)"
      ],
      "metadata": {
        "id": "USdgjr8QxdVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch을 크게 했을때\n",
        "nn_experiment(data_size=100, epoch=1000, func=func2)"
      ],
      "metadata": {
        "id": "mhp6Cy0Kw2kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 사이즈를 크게 했을때\n",
        "nn_experiment(data_size=1000, epoch=100, func=func2, lr=0.0001)"
      ],
      "metadata": {
        "id": "Wy82clXjzl84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# func1 로 실험\n",
        "nn_experiment(data_size=100, epoch=100, func=func1)"
      ],
      "metadata": {
        "id": "TwKjK-notQ8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGZZAqWEtQ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1W_aT6dR2bi"
      }
    }
  ]
}